{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7FGRjHCB6Ja"
      },
      "source": [
        "### In order for Python to find the Spark, download the findspark library and start it with findspark.init() function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkyHMADBB8mz",
        "outputId": "e14fe9fa-776b-4f82-f019-0f83ce42c926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=6350dd3766bf0c81b5c8cb90872011eb93e2987faf5c7ea02c364b268863bb4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIZK1XpTB6Je"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbtVSpfcB6Jg"
      },
      "source": [
        "### In order to work with RDDs, we need to create a SparkContext."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWC5SM0kB6Jg"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.conf import SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uvUrgUaB6Jg"
      },
      "source": [
        "\n",
        "## Since we write local [*] in the master, it will use all cores in our machine. If we said local [4] it will work with 4 cores.\n",
        "\n",
        "## getOrCreate is used to create a SparkSession if not present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq0mWEiTB6Jh"
      },
      "outputs": [],
      "source": [
        "spark=SparkSession.builder\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .appName(\"WordCount\")\\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-7py0osB6Ji"
      },
      "outputs": [],
      "source": [
        "sc=spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUTGFgkoB6Ji"
      },
      "source": [
        "## Read Data - RomeoJuliet Txt File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsDroEsAB6Jj"
      },
      "outputs": [],
      "source": [
        "veri_dosyasi=\"romeojuliet.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIt19grYB6Jj"
      },
      "outputs": [],
      "source": [
        "shakespeare_rdd=sc.textFile(veri_dosyasi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfvCZGKrB6Jj",
        "outputId": "bc772c18-63a8-4f9d-ed55-201d75f6f258"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " \"                    WILLIAM SHAKESPEARE'S\",\n",
              " '',\n",
              " '                       ROMEO & JULIET',\n",
              " '',\n",
              " '   ADAPTED FOR THE SCREEN BY CRAIG PEARCE AND BAZ LUHRMANN',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '                                       FINAL SHOOTING SCRIPT',\n",
              " '',\n",
              " '                                             October 6, 1995',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'EXT.  HIGHWAY.  AFTERNOON.',\n",
              " '',\n",
              " 'A ribbon of freeway stretching into a blue and pink late',\n",
              " 'afternoon sky. A huge dark sedan, windows tinted gold,',\n",
              " 'headlights blazing, powers directly for us.',\n",
              " '',\n",
              " 'CUT TO: A heavy, low-slung, pickup truck traveling toward',\n",
              " 'the sedan.',\n",
              " '',\n",
              " 'WIDE SHOT: Sky, freeway, the cars closing.',\n",
              " '',\n",
              " 'TIGHT ON: The sedan.',\n",
              " '',\n",
              " 'TIGHT ON: The pickup.',\n",
              " '',\n",
              " 'Like thunderous, jousting opponents, the cars pass in a',\n",
              " 'deafening cacophony of noise.',\n",
              " '',\n",
              " 'INT.  TRUCK.  AFTERNOON.',\n",
              " '',\n",
              " 'TIGHT ON: The fat face of GREGORY, yelling at the',\n",
              " 'disappearing sedan.',\n",
              " '',\n",
              " '                         GREGORY',\n",
              " '            A dog of the house of Capulet moves',\n",
              " '            me!',\n",
              " '',\n",
              " 'He and the pimply-faced front-seat passenger, SAMPSON,',\n",
              " 'explode with laughter.',\n",
              " '',\n",
              " 'The red-haired driver BENVOLIO, keeps his eyes on the road.',\n",
              " '',\n",
              " 'EXT.  EXIT RAMP.  AFTERNOON.',\n",
              " '',\n",
              " 'The truck spirals down an exit ramp and screeches into busy',\n",
              " 'driveway of a large gas station.',\n",
              " '',\n",
              " 'EXT.  GAS STATION.  AFTERNOON.',\n",
              " '',\n",
              " 'Attendants immediately run to the truck.  Two clean',\n",
              " 'windshields and duco, the third fills the gas tank.',\n",
              " '',\n",
              " 'INT.  TRUCK.  AFTERNOON.',\n",
              " '',\n",
              " 'Gregory in the back seat is boasting outrageously.',\n",
              " '',\n",
              " '                         GREGORY',\n",
              " '            A dog of that house shall move me',\n",
              " '            to stand.  I will take the wall of',\n",
              " '            any man or maid of Capulets.',\n",
              " '',\n",
              " 'Sampson, sarcastically.',\n",
              " '',\n",
              " '                         SAMPSON',\n",
              " '            That shows thee a weak slave.  For',\n",
              " '            the weakest goes to the wall.',\n",
              " '',\n",
              " '                         GREGORY',\n",
              " \"            'Tis true; and therefore women,\",\n",
              " '            being the weaker vessels, are ever',\n",
              " '            thrust to the wall.  Therefore, I']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "shakespeare_rdd.take(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfixbGDjB6Jk",
        "outputId": "8c9fbbeb-6107-4dd5-ce43-559fd60c15d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6247"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "shakespeare_rdd.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNTKc3mFB6Jk"
      },
      "source": [
        "# Remove Punctuation and Transform All Words to Lowercase.\n",
        "\n",
        "### To exclude punctuation values and convert all words to lowercase, we wrote a function like the one below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC1J4IDgB6Jk"
      },
      "outputs": [],
      "source": [
        "def lower_clean_str(x):\n",
        "  punc='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
        "  lowercased_str = x.lower()\n",
        "  for ch in punc:\n",
        "    lowercased_str = lowercased_str.replace(ch, '')\n",
        "  return lowercased_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTDZWGtJB6Jl"
      },
      "outputs": [],
      "source": [
        "shakespeare_rdd = shakespeare_rdd.map(lower_clean_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGn40f7vB6Jl",
        "outputId": "4f74698b-98f3-4276-9f19-a8a4c47e5b9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '                    william shakespeares',\n",
              " '',\n",
              " '                       romeo  juliet',\n",
              " '',\n",
              " '   adapted for the screen by craig pearce and baz luhrmann',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '                                       final shooting script',\n",
              " '',\n",
              " '                                             october 6 1995',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'ext  highway  afternoon']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "shakespeare_rdd.take(40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyMnx3tNB6Jl"
      },
      "source": [
        "## We use split function to separate the words in all lines ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHGlyDNjB6Jl"
      },
      "outputs": [],
      "source": [
        "shakespeare_rdd=shakespeare_rdd.flatMap(lambda satir: satir.split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcTDj6vTB6Jm",
        "outputId": "b36d591e-dbb2-4e08-bafb-8868c1771ce6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '', '', '', '']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "shakespeare_rdd.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LTyypXeB6Jm"
      },
      "source": [
        "## We do a filtering below to exclude whitespaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2j2g_k3B6Jm"
      },
      "outputs": [],
      "source": [
        "shakespeare_rdd = shakespeare_rdd.filter(lambda x:x!='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhpo1E0aB6Jm",
        "outputId": "ba76df80-5f21-4368-f020-c8d91c8a542d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['william', 'shakespeares', 'romeo', 'juliet']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "shakespeare_rdd.take(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akm8ReLvB6Jn"
      },
      "source": [
        "## Count how many times each word occurs.\n",
        "### To make this calculation we can apply the “reduceByKey” transformation on (key,val) pair RDD. We need to first convert “shakespeare_rdd” to (key,val) pair RDD.\n",
        "\n",
        "### In this new (key,val) pair RDD (shakespeare_count), key is the word and val is 1 for each word in RDD (1 represents the number for the each word in “shakespeare_rdd”).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tffkiAVTB6Jn"
      },
      "outputs": [],
      "source": [
        "shakespeare_count=shakespeare_rdd.map(lambda  word:(word,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LIvuHdrB6Jn",
        "outputId": "58f9039e-c9e5-4345-e3e3-9ad0bdf9c494"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('william', 1), ('shakespeares', 1), ('romeo', 1), ('juliet', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "shakespeare_count.take(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxZiPg3jB6Jn"
      },
      "source": [
        "## Apply ReduceByKey to find frequent words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN2cLNExB6Jo"
      },
      "outputs": [],
      "source": [
        "shakespeare_count_RBK=shakespeare_count.reduceByKey(lambda x,y:(x+y)).sortByKey()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyxexgJEB6Jo",
        "outputId": "482b809a-ca32-465a-84ff-9b645c6e628d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1995', 1),\n",
              " ('21', 1),\n",
              " ('6', 1),\n",
              " ('60', 2),\n",
              " ('9mm', 2),\n",
              " ('a', 563),\n",
              " ('abandoned', 1),\n",
              " ('able', 1),\n",
              " ('about', 3),\n",
              " ('above', 12),\n",
              " ('abra', 24),\n",
              " ('abras', 3),\n",
              " ('abroad', 1),\n",
              " ('abrupt', 1),\n",
              " ('abruptly', 5),\n",
              " ('absolved', 1),\n",
              " ('abuse', 2),\n",
              " ('abuses', 1),\n",
              " ('accidentally', 1),\n",
              " ('accompanied', 1),\n",
              " ('according', 1),\n",
              " ('accusation', 1),\n",
              " ('accustomed', 2),\n",
              " ('ache', 1),\n",
              " ('aches', 1),\n",
              " ('achingly', 2),\n",
              " ('acoustic', 1),\n",
              " ('across', 24),\n",
              " ('actually', 1),\n",
              " ('adagio', 1),\n",
              " ('adapted', 1),\n",
              " ('address', 1),\n",
              " ('addressed', 1),\n",
              " ('addresses', 1),\n",
              " ('adept', 1),\n",
              " ('adieu', 4),\n",
              " ('adjacent', 1),\n",
              " ('adjoining', 1),\n",
              " ('adjust', 1),\n",
              " ('admired', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "shakespeare_count_RBK.take(40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PVHaaqXB6Jo"
      },
      "source": [
        "### We want to sort the most frequent words in descending order. As the first step, we switch (key,val) pairs as (val,key)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSlQny9cB6Jo"
      },
      "outputs": [],
      "source": [
        "shakespeare_count_RBK=shakespeare_count_RBK.map(lambda x:(x[1],x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ3nO51EB6Jo",
        "outputId": "cc2f8d44-724f-4065-87a7-da2797e6a07b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, '1995'), (1, '21'), (1, '6'), (2, '60'), (2, '9mm')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "shakespeare_count_RBK.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FbAjh62B6Jp"
      },
      "source": [
        "## We see that the most common word is \"the\". However, these values are words that we call stopwords which brings value to our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4lGNCMhB6Jp",
        "outputId": "36d0cd99-b28e-4693-bc7b-7e9ad6cf1b5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1372, 'the'),\n",
              " (563, 'a'),\n",
              " (506, 'to'),\n",
              " (469, 'of'),\n",
              " (464, 'romeo'),\n",
              " (461, 'and'),\n",
              " (258, 'in'),\n",
              " (251, 'juliet'),\n",
              " (246, 'is'),\n",
              " (224, 'i')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "shakespeare_count_RBK.sortByKey(False).take(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SKZMj_MB6Jp"
      },
      "source": [
        "## To exclude stopwords words, we download the nltk library and get the list of English stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7NFKaOVB6Jp"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC7nhc3UB6Jp",
        "outputId": "cb97f936-19b8-4249-968e-985e83196a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb7TS-GjB6Jq",
        "outputId": "240219fd-9e66-424d-b3b7-57e7a361e927"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords =stopwords.words('english')\n",
        "stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84_s8T9YB6Jq"
      },
      "source": [
        "## When we exclude stopwords values, we see that the word \"romeo\" is the most common."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5EwA4QqB6Jq"
      },
      "outputs": [],
      "source": [
        "shakespeare_count_RBK = shakespeare_count_RBK.filter(lambda x: x[1] not in stopwords).sortByKey(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boCySEHvB6Jq",
        "outputId": "c1320c1a-386e-4797-d239-fe1d180f4e65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(464, 'romeo'),\n",
              " (251, 'juliet'),\n",
              " (143, 'mercutio'),\n",
              " (133, 'capulet'),\n",
              " (114, 'thou'),\n",
              " (111, 'benvolio'),\n",
              " (111, 'night'),\n",
              " (98, 'father'),\n",
              " (97, 'ext'),\n",
              " (96, 'close'),\n",
              " (96, 'nurse'),\n",
              " (92, 'cont'),\n",
              " (88, 'int'),\n",
              " (87, 'cut'),\n",
              " (84, 'car'),\n",
              " (82, 'love'),\n",
              " (81, 'laurence'),\n",
              " (79, 'tybalt'),\n",
              " (71, 'gloria'),\n",
              " (66, 'day')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "shakespeare_count_RBK.sortByKey(False).take(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mge8dveVB6Jq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}